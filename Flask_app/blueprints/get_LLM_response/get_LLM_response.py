import os
import json
from h2ogpte import H2OGPTE
from flask import Blueprint, request
from utils import rag_chat, extract_json_string
from blueprints.get_LLM_response.prompts import MEETING_SYSTEM_PROMPT, MAIN_PROMPT, generate_sentiment_prompt

# Get the H2O API key from environment variables
H2O_API_KEY = os.getenv("H2O_API_KEY")


def _create_collection():
    """
    Create a new collection in H2OGPTE and return the collection id and client instance.
    Args:
        None
        client (h2ogpte.H2OGPTE object): The client object used to connect to the chat session.
        chat_session_id (str): The ID of the chat session.
        main_prompt (str): The main prompt for the LLM.
        system_prompt (str): The system prompt for the LLM.

    Returns:
        Tuple: A tuple containing the collection_id and the client object.
        collection_id  (str) : The ID of the collection created in H2O.ai.
        client object (h2ogpte.H2OGPTE object): The client object used to connect to the chat session.
        h2ogpte.types.ChatMessage Object: The response generated by the RAG model.

    """
    client = H2OGPTE(
        address='https://h2ogpte.genai.h2o.ai',
        api_key= H2O_API_KEY,
    )
    # Create a new collection
    collection_id = client.create_collection(
        name='Temp_Meeting_Collection_test_redirect1',
        description='Information related to the Meeting hosted',
    ) 
    return (collection_id, client)

def _upload_to_collection(files, collection_id, client):
    """
    Upload files to the collection in H2OGPTE and return the list of document ids.

    Args:
        files (list): A list of files from the frontend to be uploaded.
        collection_id (str): The ID of the collection in H2O.ai.
        client (h2ogpte.H2OGPTE object): The H2OGPTE client object used to interact with H2O.ai.

    Returns:
        list (List[str]): A list of document IDs for the uploaded files.
    """
    doc_id_list = []
    os.makedirs("./temp/", exist_ok=True) # create temporary folder for temp files
    for file in files:
        print("currently trying to index file")
        file_name = file.filename
        file.save(f"./temp/{file_name}")  # Save the file temporarily
        with open(f"./temp/{file_name}", 'rb') as f:
            doc_id = client.upload(file_name, f)
            doc_id_list.append(doc_id)
    print(doc_id_list)
    client.ingest_uploads(collection_id, doc_id_list)
    return doc_id_list

get_LLM_response_bp = Blueprint('get_LLM_response', __name__)

@get_LLM_response_bp.route('/get_LLM_response', methods=['POST'])
def get_LLM_response():
    """
    Endpoint for handling initial request to get an LLM response.

    This function receives a POST request with the files to be uploaded onto H2O.ai.

    The function performs the following steps:
    1. Initializes an H2OGPTE client and creates a new H2O.ai collection.
    2. Uploads the files to the H2O.ai collection.
    3. Creates a new chat session in H2O.ai.
    4. Retrieves the meeting summary response using the RAG chat model.
    5. Generates a sentiment prompt based on the meeting summary response.
    6. Retrieves the sentiment response using the RAG chat model.
    7. Extracts the JSON string from the sentiment response.
    8. Parses the JSON string into a dictionary.
    9. Adds the doc_id_list, collection_id, and chat_session_id to the response dictionary.
    10. Returns the response dictionary as a JSON string.

    Returns:
    A JSON string containing the response dictionary.
    """
    print("Currently at get_LLM_response")
    file_data = request.files.getlist('file')
    print(file_data)

    h2o_collection_id, h2o_client = _create_collection()
    print("Tryna upload to collection")
    doc_id_list = _upload_to_collection(file_data, h2o_collection_id, h2o_client)
    print("done uploading")

    chat_session_id = h2o_client.create_chat_session(h2o_collection_id)

    print("Getting initial meeting response")
    meeting_summary_response = rag_chat(h2o_client, chat_session_id, MAIN_PROMPT, MEETING_SYSTEM_PROMPT)

    print("Getting sentiment response")
    sentiment_prompt = generate_sentiment_prompt(meeting_summary_response.content)
    print(sentiment_prompt)
    sentiment_reply = rag_chat(h2o_client, chat_session_id, sentiment_prompt, MEETING_SYSTEM_PROMPT)

    json_string = extract_json_string(sentiment_reply.content) 
    response_dic = json.loads(json_string)
    response_dic["doc_id_list"] = doc_id_list
    response_dic["collection_id"] = h2o_collection_id
    response_dic["chat_session_id"] = chat_session_id
    return json.dumps(response_dic)
